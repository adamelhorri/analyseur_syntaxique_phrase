class Tokenizer:
    def __init__(self):
        pass

    def tokenize(self(tokens: list) -> list:
        pass

    def is_punctuation(self():
        pass

    def split_tokens(self():
        pass

    def handle_composite_words(self():
        pass

